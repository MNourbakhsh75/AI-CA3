{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence - Computer Assignment 3 - Bayesian Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mehrdad Nourbakhsh(810194418)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we want to use Bayes rule for classifying news based on a short description of that news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset with nearly 23000 news. each news has a category. we want to create a model to classify the category of that news based on the short description of that news. we read the dataset from .csv file and load that into a panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Katherine LaGrave, ContributorTravel writer an...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>EccentriCities: Bingo Parties, Paella and Isla...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eccentric...</td>\n",
       "      <td>Påskekrim is merely the tip of the proverbial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ben Hallman</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>Lawyers Are Now The Driving Force Behind Mortg...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/mortgage-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Jessica Misener</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>Madonna 'Truth Or Dare' Shoe Line To Debut Thi...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/madonna-s...</td>\n",
       "      <td>Madonna is slinking her way into footwear now,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Victor and Mary, Contributor\\n2Sense-LA.com</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>Sophistication and Serenity on the Las Vegas S...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/las-vegas...</td>\n",
       "      <td>But what if you're a 30-something couple that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Emily Cohn, Contributor</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>It's Still Pretty Hard For Women To Get Free B...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/free-birt...</td>\n",
       "      <td>Obamacare was supposed to make birth control f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            authors        category  \\\n",
       "0      0  Katherine LaGrave, ContributorTravel writer an...          TRAVEL   \n",
       "1      1                                        Ben Hallman        BUSINESS   \n",
       "2      2                                    Jessica Misener  STYLE & BEAUTY   \n",
       "3      3        Victor and Mary, Contributor\\n2Sense-LA.com          TRAVEL   \n",
       "4      4                            Emily Cohn, Contributor        BUSINESS   \n",
       "\n",
       "         date                                           headline  \\\n",
       "0  2014-05-07  EccentriCities: Bingo Parties, Paella and Isla...   \n",
       "1  2014-06-09  Lawyers Are Now The Driving Force Behind Mortg...   \n",
       "2  2012-03-12  Madonna 'Truth Or Dare' Shoe Line To Debut Thi...   \n",
       "3  2013-12-17  Sophistication and Serenity on the Las Vegas S...   \n",
       "4  2015-03-19  It's Still Pretty Hard For Women To Get Free B...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/eccentric...   \n",
       "1  https://www.huffingtonpost.com/entry/mortgage-...   \n",
       "2  https://www.huffingtonpost.com/entry/madonna-s...   \n",
       "3  https://www.huffingtonpost.com/entry/las-vegas...   \n",
       "4  https://www.huffingtonpost.com/entry/free-birt...   \n",
       "\n",
       "                                   short_description  \n",
       "0  Påskekrim is merely the tip of the proverbial ...  \n",
       "1                                                NaN  \n",
       "2  Madonna is slinking her way into footwear now,...  \n",
       "3  But what if you're a 30-something couple that ...  \n",
       "4  Obamacare was supposed to make birth control f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = pd.read_csv('Attachment/data.csv')\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each news has some other information too rather than the short description (e.g headline, authors). but we ignore them and use only words of the short description to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should preprocess the data and use the result for the model. we want to normalize the short description.\n",
    "we use nltk library for normalizing the text.normalization include these steps:\n",
    "* converting uppercase to lowercase\n",
    "* removing punctuation signs\n",
    "* removing numbers\n",
    "* converting each text into a list of words\n",
    "* removing stop words\n",
    "* using lemmatization to remove inflectional endings only and to return the base form of a word\n",
    "\n",
    "If we don't convert all words to lowercase, our model might treat a word which is at the beginning of a sentence with a capital letter, different from the same word which appears later in the sentence but without any capital latter. this might influence our model accuracy. thus we convert all letters to lowercase.\n",
    "\n",
    "In our model, we use words frequency and occurrences of them in the text. we want to find relevant results not only for the exact expression but also for the other possible forms of the words we used. for this purpose we use lemmatization. lemmatization helps us to treat all possible forms of a word as an individual word and this can improve our model with increasing word frequency for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Katherine LaGrave, ContributorTravel writer an...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>EccentriCities: Bingo Parties, Paella and Isla...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eccentric...</td>\n",
       "      <td>Påskekrim is merely the tip of the proverbial ...</td>\n",
       "      <td>[påskekrim, merely, tip, proverbial, iceberg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ben Hallman</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>Lawyers Are Now The Driving Force Behind Mortg...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/mortgage-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Jessica Misener</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>Madonna 'Truth Or Dare' Shoe Line To Debut Thi...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/madonna-s...</td>\n",
       "      <td>Madonna is slinking her way into footwear now,...</td>\n",
       "      <td>[madonna, slink, way, footwear, truth, dare, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Victor and Mary, Contributor\\n2Sense-LA.com</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>Sophistication and Serenity on the Las Vegas S...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/las-vegas...</td>\n",
       "      <td>But what if you're a 30-something couple that ...</td>\n",
       "      <td>[something, couple, shy, away, table, dance, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Emily Cohn, Contributor</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>It's Still Pretty Hard For Women To Get Free B...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/free-birt...</td>\n",
       "      <td>Obamacare was supposed to make birth control f...</td>\n",
       "      <td>[obamacare, suppose, make, birth, control, fre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            authors        category  \\\n",
       "0      0  Katherine LaGrave, ContributorTravel writer an...          TRAVEL   \n",
       "1      1                                        Ben Hallman        BUSINESS   \n",
       "2      2                                    Jessica Misener  STYLE & BEAUTY   \n",
       "3      3        Victor and Mary, Contributor\\n2Sense-LA.com          TRAVEL   \n",
       "4      4                            Emily Cohn, Contributor        BUSINESS   \n",
       "\n",
       "         date                                           headline  \\\n",
       "0  2014-05-07  EccentriCities: Bingo Parties, Paella and Isla...   \n",
       "1  2014-06-09  Lawyers Are Now The Driving Force Behind Mortg...   \n",
       "2  2012-03-12  Madonna 'Truth Or Dare' Shoe Line To Debut Thi...   \n",
       "3  2013-12-17  Sophistication and Serenity on the Las Vegas S...   \n",
       "4  2015-03-19  It's Still Pretty Hard For Women To Get Free B...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/eccentric...   \n",
       "1  https://www.huffingtonpost.com/entry/mortgage-...   \n",
       "2  https://www.huffingtonpost.com/entry/madonna-s...   \n",
       "3  https://www.huffingtonpost.com/entry/las-vegas...   \n",
       "4  https://www.huffingtonpost.com/entry/free-birt...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Påskekrim is merely the tip of the proverbial ...   \n",
       "1                                                NaN   \n",
       "2  Madonna is slinking her way into footwear now,...   \n",
       "3  But what if you're a 30-something couple that ...   \n",
       "4  Obamacare was supposed to make birth control f...   \n",
       "\n",
       "                                               words  \n",
       "0  [påskekrim, merely, tip, proverbial, iceberg, ...  \n",
       "1                                                 []  \n",
       "2  [madonna, slink, way, footwear, truth, dare, p...  \n",
       "3  [something, couple, shy, away, table, dance, e...  \n",
       "4  [obamacare, suppose, make, birth, control, fre...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataFrame.short_description\n",
    "data = data.fillna('')\n",
    "data = data.str.lower()\n",
    "data = data.str.replace('[^\\w\\s]',' ')\n",
    "data = data.str.replace('\\d+', '')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordsList = data.apply(word_tokenize)\n",
    "wordsList = wordsList.apply(lambda x: [item for item in x if item not in stopWords])\n",
    "wordsList = wordsList.apply(lambda x: [lemmatizer.lemmatize(y, pos=\"v\") for y in x])\n",
    "dataFrame['words'] = wordsList\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate our data into two parts. the train set and evaluate set. we use 80 percent of data as train set and 20 percent as evaluate set. we want to have all sorts of news. if we choose 80 percent of real data as train set, we may have a set with only one or two categories, therefore, our model can not detect other categories as well. we have to create a train set with good diversity from all of the categories. \n",
    "\n",
    "for each category, we choose a random subset of that category (80 percent) and then combine those subsets to create our train set and the remaining 20 percent of each category for evaluate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6155</td>\n",
       "      <td>6155</td>\n",
       "      <td>Dr. Patty Ann Tublin, ContributorRelationship ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>'Paleo-ing' Your Business and Career Is the Ke...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/paleoing-...</td>\n",
       "      <td>So what could paleo eating and success in your...</td>\n",
       "      <td>[could, paleo, eat, success, business, career,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20153</td>\n",
       "      <td>20153</td>\n",
       "      <td>Suzy Strutner</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>50 Fictional Places You Can Visit In Real Life</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/movie-loc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15758</td>\n",
       "      <td>15758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2012-07-19</td>\n",
       "      <td>Marrakech, Morocco Sees Hotel Boom (PHOTOS)</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/marrakech...</td>\n",
       "      <td>Marrakech has been having a moment (in the tra...</td>\n",
       "      <td>[marrakech, moment, travel, press, least, sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21273</td>\n",
       "      <td>21273</td>\n",
       "      <td>Ann Francke, Contributor\\nManagement Expert an...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2013-03-02</td>\n",
       "      <td>Why Marissa Mayer Makes Me Mad as a Mom and a ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/why-maris...</td>\n",
       "      <td>Mayer's decision, ironically, is a huge diss o...</td>\n",
       "      <td>[mayer, decision, ironically, huge, diss, prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>Michelle Persad</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>2012-11-17</td>\n",
       "      <td>Isla Fisher Channels Old Hollywood Glamour (PH...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/isla-fish...</td>\n",
       "      <td>Red lipstick never looked so good.</td>\n",
       "      <td>[red, lipstick, never, look, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                            authors  \\\n",
       "6155    6155  Dr. Patty Ann Tublin, ContributorRelationship ...   \n",
       "20153  20153                                      Suzy Strutner   \n",
       "15758  15758                                                NaN   \n",
       "21273  21273  Ann Francke, Contributor\\nManagement Expert an...   \n",
       "647      647                                    Michelle Persad   \n",
       "\n",
       "             category        date  \\\n",
       "6155         BUSINESS  2015-03-06   \n",
       "20153          TRAVEL  2014-10-05   \n",
       "15758          TRAVEL  2012-07-19   \n",
       "21273        BUSINESS  2013-03-02   \n",
       "647    STYLE & BEAUTY  2012-11-17   \n",
       "\n",
       "                                                headline  \\\n",
       "6155   'Paleo-ing' Your Business and Career Is the Ke...   \n",
       "20153     50 Fictional Places You Can Visit In Real Life   \n",
       "15758        Marrakech, Morocco Sees Hotel Boom (PHOTOS)   \n",
       "21273  Why Marissa Mayer Makes Me Mad as a Mom and a ...   \n",
       "647    Isla Fisher Channels Old Hollywood Glamour (PH...   \n",
       "\n",
       "                                                    link  \\\n",
       "6155   https://www.huffingtonpost.com/entry/paleoing-...   \n",
       "20153  https://www.huffingtonpost.com/entry/movie-loc...   \n",
       "15758  https://www.huffingtonpost.com/entry/marrakech...   \n",
       "21273  https://www.huffingtonpost.com/entry/why-maris...   \n",
       "647    https://www.huffingtonpost.com/entry/isla-fish...   \n",
       "\n",
       "                                       short_description  \\\n",
       "6155   So what could paleo eating and success in your...   \n",
       "20153                                                NaN   \n",
       "15758  Marrakech has been having a moment (in the tra...   \n",
       "21273  Mayer's decision, ironically, is a huge diss o...   \n",
       "647                   Red lipstick never looked so good.   \n",
       "\n",
       "                                                   words  \n",
       "6155   [could, paleo, eat, success, business, career,...  \n",
       "20153                                                 []  \n",
       "15758  [marrakech, moment, travel, press, least, sinc...  \n",
       "21273  [mayer, decision, ironically, huge, diss, prod...  \n",
       "647                   [red, lipstick, never, look, good]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel = dataFrame[dataFrame['category'] == 'TRAVEL']\n",
    "business = dataFrame[dataFrame['category'] == 'BUSINESS']\n",
    "sb = dataFrame[dataFrame['category'] == 'STYLE & BEAUTY']\n",
    "trainTravel = travel.sample(frac=0.8)\n",
    "evaluateTravel = travel.drop(trainTravel.index)\n",
    "trainBusiness = business.sample(frac=0.8)\n",
    "evaluateBusiness = business.drop(trainBusiness.index)\n",
    "trainSB = sb.sample(frac=0.8)\n",
    "evaluateSB = sb.drop(trainSB.index)\n",
    "# trainData = pd.concat([trainTravel,trainBusiness, trainSB])\n",
    "# trainData = trainData.sample(frac=1)\n",
    "evaluateData = pd.concat([evaluateSB,evaluateBusiness, evaluateTravel])\n",
    "evaluateData = evaluateData.sample(frac=1)\n",
    "# trainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our train set, we should train our model with this set. \n",
    "for this purpose, we use Bayes rule.\n",
    "\n",
    "$$ P(c|x) = \\frac{P(x|c)\\times P(c)}{P(x)} $$\n",
    "\n",
    "As we can see, Bayes rule has 4 parts: Posterior, Likelihood, Prior and Evidence.in order to use this rule, we should define each part of the Bayes rule for our project.\n",
    "\n",
    "The posterior probability is the probability of a category given the words in the news. we use Bayes rule to calculate this probability.\n",
    "\n",
    "$$ posterior = {P(category | x_0, x_1, x_2, ...,  x_n)} $$\n",
    "\n",
    "which is $x_n$ is the n-th word of that news.\n",
    "\n",
    "We define the probability of each category as the prior probability which means how probable is it for a news to be for a certain category.\n",
    "\n",
    "We define the likelihood as the probability of each word of a news given the category which means how probable it is for that category to use that word. in other words, the likelihood probability is:\n",
    "\n",
    "$$ likelihood = {P(x_0, x_1, x_2, ...,  x_n|category)} $$\n",
    "\n",
    "Since the probability of existing a word in a certain category is independent of the probability of existing another word in that category for each news, we can multiply these probabilities to calculate our conditional probability.\n",
    "\n",
    "$$ likelihood = {P(x_0|category)\\times P(x_1|category) \\times P(x_2|category) \\times ... \\times P(x_n|category)} $$\n",
    "\n",
    "The evidence is the probabiliy of all words that we have in a given news.\n",
    "\n",
    "$$ evidence = {P(x_0, x_1, x_2, ...,  x_n)} $$\n",
    "\n",
    "Since we are going to compare the posterior probabilities for each category and in each category the evidence probability is the same as other categories, thus we don't need to calculate the evidence probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part $\\mathrm{I}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we want to train our model for only two categories. TRAVEL category and BUSINESS category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "travelWords = trainTravel.words.values\n",
    "travelWords = list(itertools.chain.from_iterable(travelWords))\n",
    "BusinessWords = trainBusiness.words.values\n",
    "BusinessWords = list(itertools.chain.from_iterable(BusinessWords))\n",
    "allTravelAndBusinessWord = list(map(''.join, set(itertools.chain(travelWords, BusinessWords))))\n",
    "travelWordsCount = dict(collections.Counter(travelWords))\n",
    "BusinessWordsCount = dict(collections.Counter(BusinessWords))\n",
    "newDataFrame = pd.DataFrame(columns=['Word','Travel occurrences','Business occurrences'])\n",
    "for word in allTravelAndBusinessWord:\n",
    "    to = 0\n",
    "    bo = 0\n",
    "    if word in travelWordsCount:\n",
    "        to = travelWordsCount[word]\n",
    "    if word in BusinessWordsCount:\n",
    "        bo = BusinessWordsCount[word]\n",
    "    newDataFrame = newDataFrame.append({'Word' : word,'Travel occurrences' : to,'Business occurrences' : bo},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new data frame. for each word, we calculate the probability of that word given the category. in fact, we calculate $ P(word | category) $ for each word in our training set (in this case out training set contain only two mentioned categories).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculating the conditional probability we use the Laplace Smoothing. since we multiply the conditional probabilities in order to calculate the likelihood, if we have a word that used only one time in one category, the likelihood probability for other categories will be zero even if other conditional probabilities have a high value. Laplace smoothing is used to solve the problem of zero probability.\n",
    "\n",
    "$$ P(word|category) =  \\frac{O(word,category) + \\alpha}{S(words,categor) + |A|\\alpha} $$\n",
    "\n",
    "We use this formula to calculate the conditional probability. O(word, category) is the word occurrences in that category, S(words, category) is the number of all words in that category and |A| is the number of distinct words in our train set.\n",
    "alpha is a constant which is used to solve zero probability problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Travel occurrences</th>\n",
       "      <th>Business occurrences</th>\n",
       "      <th>Travel Probability</th>\n",
       "      <th>Business Probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>farris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.46652e-06</td>\n",
       "      <td>2.45833e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>entrepreneurship</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.46652e-06</td>\n",
       "      <td>0.000204861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walmart</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4.46652e-06</td>\n",
       "      <td>0.000549027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>martyr</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.23326e-05</td>\n",
       "      <td>8.19444e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shaft</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.46652e-06</td>\n",
       "      <td>2.45833e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>frequencies</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33996e-05</td>\n",
       "      <td>8.19444e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bicycle</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7.59308e-05</td>\n",
       "      <td>8.19444e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>carefully</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.23326e-05</td>\n",
       "      <td>5.73611e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>file</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>6.69978e-05</td>\n",
       "      <td>0.000319583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>segways</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33996e-05</td>\n",
       "      <td>8.19444e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17742 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Travel occurrences Business occurrences Travel Probability  \\\n",
       "Word                                                                          \n",
       "farris                            0                    1        4.46652e-06   \n",
       "entrepreneurship                  0                   12        4.46652e-06   \n",
       "walmart                           0                   33        4.46652e-06   \n",
       "martyr                            2                    0        2.23326e-05   \n",
       "shaft                             0                    1        4.46652e-06   \n",
       "...                             ...                  ...                ...   \n",
       "frequencies                       1                    0        1.33996e-05   \n",
       "bicycle                           8                    0        7.59308e-05   \n",
       "carefully                         2                    3        2.23326e-05   \n",
       "file                              7                   19        6.69978e-05   \n",
       "segways                           1                    0        1.33996e-05   \n",
       "\n",
       "                 Business Probability  \n",
       "Word                                   \n",
       "farris                    2.45833e-05  \n",
       "entrepreneurship          0.000204861  \n",
       "walmart                   0.000549027  \n",
       "martyr                    8.19444e-06  \n",
       "shaft                     2.45833e-05  \n",
       "...                               ...  \n",
       "frequencies               8.19444e-06  \n",
       "bicycle                   8.19444e-06  \n",
       "carefully                 5.73611e-05  \n",
       "file                      0.000319583  \n",
       "segways                   8.19444e-06  \n",
       "\n",
       "[17742 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "newDataFrame['Travel Probability'] = (newDataFrame['Travel occurrences'] + alpha) / (newDataFrame['Travel occurrences'].sum() + (len(set(travelWords + BusinessWords))*alpha))\n",
    "newDataFrame['Business Probability'] = (newDataFrame['Business occurrences'] + alpha) / (newDataFrame['Business occurrences'].sum() + (len(set(travelWords + BusinessWords))*alpha))\n",
    "newDataFrame = newDataFrame.set_index('Word')\n",
    "newDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "travelAndBusinessEvaluateData = pd.concat([evaluateBusiness, evaluateTravel])\n",
    "travelAndBusinessEvaluateData = travelAndBusinessEvaluateData.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the conditional probability our model is ready to test with evaluate data. for each news in evaluate set, we calculate the prior probability and for all of the words in that news, we multiply the conditional probability with prior probability in order to calculate the posterior probability. After that, we can predict the category for each news. the category with higher posterior probability is our model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>words</th>\n",
       "      <th>Travel Probability</th>\n",
       "      <th>Business Probability</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15144</td>\n",
       "      <td>15144</td>\n",
       "      <td>Kari Astrid Haugeto, Contributor\\nEntrepreneur...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>Would You Take Your Kids to Las Vegas?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/las-vegas...</td>\n",
       "      <td>Vegas may not be considered the most family-fr...</td>\n",
       "      <td>[vegas, may, consider, family, friendly, desti...</td>\n",
       "      <td>1.310353e-60</td>\n",
       "      <td>2.234789e-67</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10360</td>\n",
       "      <td>10360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Paul Krugman: Here's 1 Thing That Hasn't Chang...</td>\n",
       "      <td>https://www.huffingtonpost.comhttp://www.nytim...</td>\n",
       "      <td>It's that time of year -- the long weekend whe...</td>\n",
       "      <td>[time, year, long, weekend, gather, friends, f...</td>\n",
       "      <td>1.381914e-41</td>\n",
       "      <td>1.804279e-44</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21814</td>\n",
       "      <td>21814</td>\n",
       "      <td>Anne Z. Cooke, ContributorTravel and adventure...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>Mexico's No. 1 Baja Beach Resort: The Villa de...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/post_8715...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.248244e-01</td>\n",
       "      <td>3.751756e-01</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22644</td>\n",
       "      <td>22644</td>\n",
       "      <td>Oyster.com, Contributor\\nThe Hotel Tell-All</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>Trash Your Room At These Rock And Roll Hotels ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/unleash-y...</td>\n",
       "      <td>If you want to drop a beat, or just pick up th...</td>\n",
       "      <td>[want, drop, beat, pick, vibes, leave, behind,...</td>\n",
       "      <td>1.280896e-44</td>\n",
       "      <td>5.575987e-51</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13702</td>\n",
       "      <td>13702</td>\n",
       "      <td>Christopher Elliott, Contributor\\nAuthor, How ...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>5 Things Not To Tell A TSA Screener (VIDEO)</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/5-things-...</td>\n",
       "      <td>Dressing down a TSA agent at the airport, whil...</td>\n",
       "      <td>[dress, tsa, agent, airport, tempt, serve, use...</td>\n",
       "      <td>1.045361e-31</td>\n",
       "      <td>3.895727e-36</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20336</td>\n",
       "      <td>20336</td>\n",
       "      <td>Tom Mulhall, Contributor\\nNude Recreation Spec...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-08-29</td>\n",
       "      <td>Is Topless Sunbathing Good for American Tourism?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/america-t...</td>\n",
       "      <td>Can American tourism afford not to allow tople...</td>\n",
       "      <td>[american, tourism, afford, allow, topless, su...</td>\n",
       "      <td>2.719939e-23</td>\n",
       "      <td>9.349226e-27</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12135</td>\n",
       "      <td>12135</td>\n",
       "      <td>Suzy Strutner</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>6 Beautiful Canals You'll Probably Want To Vis...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/beautiful...</td>\n",
       "      <td>2. Monmouthshire and Brecon, South Wales Peopl...</td>\n",
       "      <td>[monmouthshire, brecon, south, wales, people, ...</td>\n",
       "      <td>1.482118e-38</td>\n",
       "      <td>5.150690e-41</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2616</td>\n",
       "      <td>2616</td>\n",
       "      <td>Peter Mandel, Contributor\\nWashington Post con...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>British Tourists Bitch About New York: Shoppin...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/british-t...</td>\n",
       "      <td>What do tourists from abroad think of travelin...</td>\n",
       "      <td>[tourists, abroad, think, travel, keen, americ...</td>\n",
       "      <td>1.803517e-33</td>\n",
       "      <td>2.389699e-42</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2012-05-20</td>\n",
       "      <td>Is Insider Trading Part Of The Fabric On Wall ...</td>\n",
       "      <td>https://www.huffingtonpost.comhttp://www.nytim...</td>\n",
       "      <td>Federal authorities today are trumpeting effor...</td>\n",
       "      <td>[federal, authorities, today, trumpet, efforts...</td>\n",
       "      <td>5.493070e-49</td>\n",
       "      <td>5.520852e-47</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9862</td>\n",
       "      <td>9862</td>\n",
       "      <td>Andres Jauregui</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-06-24</td>\n",
       "      <td>Lindsay Bien-aime, US Airways Passenger, Arres...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/lindsay-b...</td>\n",
       "      <td>\"Wouldn't any normal person see that its a no-...</td>\n",
       "      <td>[normal, person, see, win, situation, time, ge...</td>\n",
       "      <td>4.993484e-31</td>\n",
       "      <td>1.675842e-30</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2849 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                            authors  category  \\\n",
       "15144  15144  Kari Astrid Haugeto, Contributor\\nEntrepreneur...    TRAVEL   \n",
       "10360  10360                                                NaN  BUSINESS   \n",
       "21814  21814  Anne Z. Cooke, ContributorTravel and adventure...    TRAVEL   \n",
       "22644  22644        Oyster.com, Contributor\\nThe Hotel Tell-All    TRAVEL   \n",
       "13702  13702  Christopher Elliott, Contributor\\nAuthor, How ...    TRAVEL   \n",
       "...      ...                                                ...       ...   \n",
       "20336  20336  Tom Mulhall, Contributor\\nNude Recreation Spec...    TRAVEL   \n",
       "12135  12135                                      Suzy Strutner    TRAVEL   \n",
       "2616    2616  Peter Mandel, Contributor\\nWashington Post con...    TRAVEL   \n",
       "652      652                                                NaN  BUSINESS   \n",
       "9862    9862                                    Andres Jauregui    TRAVEL   \n",
       "\n",
       "             date                                           headline  \\\n",
       "15144  2013-08-04             Would You Take Your Kids to Las Vegas?   \n",
       "10360  2013-07-05  Paul Krugman: Here's 1 Thing That Hasn't Chang...   \n",
       "21814  2014-12-10  Mexico's No. 1 Baja Beach Resort: The Villa de...   \n",
       "22644  2013-02-09  Trash Your Room At These Rock And Roll Hotels ...   \n",
       "13702  2012-08-21        5 Things Not To Tell A TSA Screener (VIDEO)   \n",
       "...           ...                                                ...   \n",
       "20336  2013-08-29   Is Topless Sunbathing Good for American Tourism?   \n",
       "12135  2013-09-25  6 Beautiful Canals You'll Probably Want To Vis...   \n",
       "2616   2013-04-01  British Tourists Bitch About New York: Shoppin...   \n",
       "652    2012-05-20  Is Insider Trading Part Of The Fabric On Wall ...   \n",
       "9862   2013-06-24  Lindsay Bien-aime, US Airways Passenger, Arres...   \n",
       "\n",
       "                                                    link  \\\n",
       "15144  https://www.huffingtonpost.com/entry/las-vegas...   \n",
       "10360  https://www.huffingtonpost.comhttp://www.nytim...   \n",
       "21814  https://www.huffingtonpost.com/entry/post_8715...   \n",
       "22644  https://www.huffingtonpost.com/entry/unleash-y...   \n",
       "13702  https://www.huffingtonpost.com/entry/5-things-...   \n",
       "...                                                  ...   \n",
       "20336  https://www.huffingtonpost.com/entry/america-t...   \n",
       "12135  https://www.huffingtonpost.com/entry/beautiful...   \n",
       "2616   https://www.huffingtonpost.com/entry/british-t...   \n",
       "652    https://www.huffingtonpost.comhttp://www.nytim...   \n",
       "9862   https://www.huffingtonpost.com/entry/lindsay-b...   \n",
       "\n",
       "                                       short_description  \\\n",
       "15144  Vegas may not be considered the most family-fr...   \n",
       "10360  It's that time of year -- the long weekend whe...   \n",
       "21814                                                NaN   \n",
       "22644  If you want to drop a beat, or just pick up th...   \n",
       "13702  Dressing down a TSA agent at the airport, whil...   \n",
       "...                                                  ...   \n",
       "20336  Can American tourism afford not to allow tople...   \n",
       "12135  2. Monmouthshire and Brecon, South Wales Peopl...   \n",
       "2616   What do tourists from abroad think of travelin...   \n",
       "652    Federal authorities today are trumpeting effor...   \n",
       "9862   \"Wouldn't any normal person see that its a no-...   \n",
       "\n",
       "                                                   words  Travel Probability  \\\n",
       "15144  [vegas, may, consider, family, friendly, desti...        1.310353e-60   \n",
       "10360  [time, year, long, weekend, gather, friends, f...        1.381914e-41   \n",
       "21814                                                 []        6.248244e-01   \n",
       "22644  [want, drop, beat, pick, vibes, leave, behind,...        1.280896e-44   \n",
       "13702  [dress, tsa, agent, airport, tempt, serve, use...        1.045361e-31   \n",
       "...                                                  ...                 ...   \n",
       "20336  [american, tourism, afford, allow, topless, su...        2.719939e-23   \n",
       "12135  [monmouthshire, brecon, south, wales, people, ...        1.482118e-38   \n",
       "2616   [tourists, abroad, think, travel, keen, americ...        1.803517e-33   \n",
       "652    [federal, authorities, today, trumpet, efforts...        5.493070e-49   \n",
       "9862   [normal, person, see, win, situation, time, ge...        4.993484e-31   \n",
       "\n",
       "       Business Probability Prediction  \n",
       "15144          2.234789e-67     TRAVEL  \n",
       "10360          1.804279e-44     TRAVEL  \n",
       "21814          3.751756e-01     TRAVEL  \n",
       "22644          5.575987e-51     TRAVEL  \n",
       "13702          3.895727e-36     TRAVEL  \n",
       "...                     ...        ...  \n",
       "20336          9.349226e-27     TRAVEL  \n",
       "12135          5.150690e-41     TRAVEL  \n",
       "2616           2.389699e-42     TRAVEL  \n",
       "652            5.520852e-47   BUSINESS  \n",
       "9862           1.675842e-30   BUSINESS  \n",
       "\n",
       "[2849 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,row in travelAndBusinessEvaluateData.iterrows():\n",
    "    travelPriorProbability = len(trainTravel)/(len(trainTravel)+len(trainBusiness))\n",
    "    businessPriorProbability = len(trainBusiness)/(len(trainTravel)+len(trainBusiness))\n",
    "    words = set(row['words'])\n",
    "    for word in words:\n",
    "        if word in allTravelAndBusinessWord:\n",
    "            travelPriorProbability *= newDataFrame.at[word,'Travel Probability']\n",
    "            businessPriorProbability *= newDataFrame.at[word,'Business Probability']\n",
    "\n",
    "    travelAndBusinessEvaluateData.at[index,'Travel Probability'] = travelPriorProbability\n",
    "    travelAndBusinessEvaluateData.at[index,'Business Probability'] = businessPriorProbability\n",
    "    if travelPriorProbability >= businessPriorProbability:\n",
    "        travelAndBusinessEvaluateData.at[index,'Prediction'] = 'TRAVEL'\n",
    "    else:\n",
    "        travelAndBusinessEvaluateData.at[index,'Prediction'] = 'BUSINESS'\n",
    "travelAndBusinessEvaluateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8758426966292134 0.8128258602711157\n",
      "0.7427502338634238 0.8528464017185822\n",
      "0.8553878553878553\n"
     ]
    }
   ],
   "source": [
    "#Travel\n",
    "correctTravel = travelAndBusinessEvaluateData.loc[(travelAndBusinessEvaluateData['category'] == 'TRAVEL') & (travelAndBusinessEvaluateData['Prediction'] == 'TRAVEL')]\n",
    "correctTravel = (correctTravel.all(axis='columns')).sum()\n",
    "allOfTravel = (travelAndBusinessEvaluateData['category'] == 'TRAVEL').sum()\n",
    "allTravelPrediction = (travelAndBusinessEvaluateData['Prediction'] == 'TRAVEL').sum()\n",
    "travelRecall = correctTravel/allOfTravel\n",
    "travelPrecision = correctTravel/allTravelPrediction\n",
    "print(travelRecall,travelPrecision)\n",
    "#Business\n",
    "correctBusiness = travelAndBusinessEvaluateData.loc[(travelAndBusinessEvaluateData['category'] == 'BUSINESS') & (travelAndBusinessEvaluateData['Prediction'] == 'BUSINESS')]\n",
    "correctBusiness = (correctBusiness.all(axis='columns')).sum()\n",
    "allOfBusiness = (travelAndBusinessEvaluateData['category'] == 'BUSINESS').sum()\n",
    "allBusinessPrediction = (travelAndBusinessEvaluateData['Prediction'] == 'BUSINESS').sum()\n",
    "BusinessRecall = correctBusiness/allOfBusiness\n",
    "BusinessPrecision = correctBusiness/allBusinessPrediction\n",
    "print(BusinessRecall,BusinessPrecision)\n",
    "travelAndBusinessEvaluateData['correct'] = (travelAndBusinessEvaluateData['category'] == travelAndBusinessEvaluateData['Prediction'])\n",
    "correctDetected = (travelAndBusinessEvaluateData['correct']).sum()\n",
    "accuracy =  correctDetected / len(travelAndBusinessEvaluateData)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part $\\mathrm{II}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add third category to our model. we add STYLE & BEAUTY category to our train set and repeat all the process again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbWords = trainSB.words.values\n",
    "# sbWords = list(itertools.chain.from_iterable(sbWords))\n",
    "# allTrainDataWords = list(map(''.join, set(itertools.chain(travelWords, BusinessWords,sbWords))))\n",
    "# print(len(travelWords),len(BusinessWords),len(sbWords),len(allTrainDataWords))\n",
    "# sbWordsCount = dict(collections.Counter(sbWords))\n",
    "# travelWordsCount = dict(collections.Counter(travelWords))\n",
    "# BusinessWordsCount = dict(collections.Counter(BusinessWords))\n",
    "# print(len(travelWordsCount),len(BusinessWordsCount),len(sbWordsCount),len(allTrainDataWords))\n",
    "# allDataFrame = pd.DataFrame(columns=['Word','Travel occurrences','Business occurrences','Style & Beauty occurrences'])\n",
    "# for word in allTrainDataWords:\n",
    "#     to = 0\n",
    "#     sbo = 0\n",
    "#     bo = 0\n",
    "#     if word in travelWordsCount:\n",
    "#         to = travelWordsCount[word]\n",
    "#     if word in BusinessWordsCount:\n",
    "#         bo = BusinessWordsCount[word]\n",
    "#     if word in sbWordsCount:\n",
    "#         sbo = sbWordsCount[word]\n",
    "#     allDataFrame = allDataFrame.append({'Word' : word,'Travel occurrences' : to,'Business occurrences' : bo,'Style & Beauty occurrences' : sbo},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use Laplace smoothing here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.5\n",
    "# allDataFrame['Travel Probability'] = (allDataFrame['Travel occurrences'] + alpha) / (allDataFrame['Travel occurrences'].sum() + (len(set(travelWords + BusinessWords + sbWords))*alpha))\n",
    "# allDataFrame['Business Probability'] = allDataFrame['Business occurrences'] / (allDataFrame['Business occurrences'].sum() + (len(set(travelWords + BusinessWords + sbWords))*alpha))\n",
    "# allDataFrame['Style & Beauty Probability'] = allDataFrame['Style & Beauty occurrences'] / (allDataFrame['Style & Beauty occurrences'].sum() + (len(set(travelWords + BusinessWords + sbWords))*alpha))\n",
    "# allDataFrame = allDataFrame.set_index('Word')\n",
    "# allDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our model with our evaluation set which has all three category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,row in evaluateData.iterrows():\n",
    "#     travelPriorProbability = len(trainTravel)/(len(trainTravel)+len(trainBusiness)+len(trainSB))\n",
    "#     businessPriorProbability = len(trainBusiness)/(len(trainTravel)+len(trainBusiness)+len(trainSB))\n",
    "#     sbPriorProbability = len(trainSB)/(len(trainTravel)+len(trainBusiness)+len(trainSB))\n",
    "#     words = set(row['words'])\n",
    "#     for word in words:\n",
    "#         if word in allTrainDataWords:\n",
    "#             travelPriorProbability *= allDataFrame.at[word,'Travel Probability']\n",
    "#             businessPriorProbability *= allDataFrame.at[word,'Business Probability']\n",
    "#             sbPriorProbability *= allDataFrame.at[word,'Style & Beauty Probability']\n",
    "#     evaluateData.at[index,'Travel Probability'] = travelPriorProbability\n",
    "#     evaluateData.at[index,'Business Probability'] = businessPriorProbability\n",
    "#     evaluateData.at[index,'Style & Beauty Probability'] = sbPriorProbability\n",
    "#     if travelPriorProbability >= businessPriorProbability and travelPriorProbability >= sbPriorProbability:\n",
    "#         evaluateData.at[index,'Prediction'] = 'TRAVEL'\n",
    "#     if businessPriorProbability >= travelPriorProbability and businessPriorProbability >= sbPriorProbability:\n",
    "#         evaluateData.at[index,'Prediction'] = 'BUSINESS'\n",
    "#     if sbPriorProbability >= travelPriorProbability and sbPriorProbability>= businessPriorProbability:\n",
    "#         evaluateData.at[index,'Prediction'] = 'STYLE & BEAUTY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4071</td>\n",
       "      <td>4071</td>\n",
       "      <td>Travel + Leisure, Contributor\\nTravelandLeisur...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2012-06-28</td>\n",
       "      <td>Europe's Secret Hot Spots (PHOTOS)</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/europes-s...</td>\n",
       "      <td>The continent is so varied that even with 17 c...</td>\n",
       "      <td>[continent, vary, even, countries, share, euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14977</td>\n",
       "      <td>14977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>11 Fashion Essentials Every 30-Something Shoul...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/fashion-e...</td>\n",
       "      <td>So you've made it past your trying twenties. Y...</td>\n",
       "      <td>[make, past, try, twenties, hopefully, invest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16709</td>\n",
       "      <td>16709</td>\n",
       "      <td>Brittany Binowski</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2013-08-04</td>\n",
       "      <td>Your Weekly Travel Zen: Harbors</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/harbor-ph...</td>\n",
       "      <td>Where have you traveled for a moment of zen? E...</td>\n",
       "      <td>[travel, moment, zen, email, travel, huffingto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7382</td>\n",
       "      <td>7382</td>\n",
       "      <td>Abigail Williams</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>West Elm Is Launching Its Own Collection Of Ho...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/west-elm-...</td>\n",
       "      <td>This is not a drill.</td>\n",
       "      <td>[drill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12662</td>\n",
       "      <td>12662</td>\n",
       "      <td>Mike Sternoff, Contributor\\nDigital Journalist</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>The Running Of The Bulls Made Simple (VIDEO)</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-o...</td>\n",
       "      <td>A few years back I packed up everything I owne...</td>\n",
       "      <td>[years, back, pack, everything, own, head, eur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                            authors  \\\n",
       "4071    4071  Travel + Leisure, Contributor\\nTravelandLeisur...   \n",
       "14977  14977                                                NaN   \n",
       "16709  16709                                  Brittany Binowski   \n",
       "7382    7382                                   Abigail Williams   \n",
       "12662  12662     Mike Sternoff, Contributor\\nDigital Journalist   \n",
       "\n",
       "             category        date  \\\n",
       "4071           TRAVEL  2012-06-28   \n",
       "14977  STYLE & BEAUTY  2013-10-01   \n",
       "16709          TRAVEL  2013-08-04   \n",
       "7382           TRAVEL  2016-09-26   \n",
       "12662          TRAVEL  2012-12-10   \n",
       "\n",
       "                                                headline  \\\n",
       "4071                  Europe's Secret Hot Spots (PHOTOS)   \n",
       "14977  11 Fashion Essentials Every 30-Something Shoul...   \n",
       "16709                    Your Weekly Travel Zen: Harbors   \n",
       "7382   West Elm Is Launching Its Own Collection Of Ho...   \n",
       "12662       The Running Of The Bulls Made Simple (VIDEO)   \n",
       "\n",
       "                                                    link  \\\n",
       "4071   https://www.huffingtonpost.com/entry/europes-s...   \n",
       "14977  https://www.huffingtonpost.com/entry/fashion-e...   \n",
       "16709  https://www.huffingtonpost.com/entry/harbor-ph...   \n",
       "7382   https://www.huffingtonpost.com/entry/west-elm-...   \n",
       "12662  https://www.huffingtonpost.com/entry/running-o...   \n",
       "\n",
       "                                       short_description  \\\n",
       "4071   The continent is so varied that even with 17 c...   \n",
       "14977  So you've made it past your trying twenties. Y...   \n",
       "16709  Where have you traveled for a moment of zen? E...   \n",
       "7382                                This is not a drill.   \n",
       "12662  A few years back I packed up everything I owne...   \n",
       "\n",
       "                                                   words  \n",
       "4071   [continent, vary, even, countries, share, euro...  \n",
       "14977  [make, past, try, twenties, hopefully, invest,...  \n",
       "16709  [travel, moment, zen, email, travel, huffingto...  \n",
       "7382                                             [drill]  \n",
       "12662  [years, back, pack, everything, own, head, eur...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluateData['Correct'] = (evaluateData['category'] == evaluateData['Prediction'])\n",
    "# correctDetected = (evaluateData['Correct']).sum()\n",
    "# accuracy =  correctDetected / len(evaluateData)\n",
    "# AllOfTravel = (evaluateData['category'] == 'TRAVEL').sum()\n",
    "# AllOfBusiness = (evaluateData['category'] == 'BUSINESS').sum()\n",
    "# AllOfSB = (evaluateData['category'] == 'STYLE & BEAUTY').sum()\n",
    "# correctTravel = (evaluateData.loc[(evaluateData['Correct'] == True) & (dataFrame['category'] == 'TRAVEL')].all(axis='columns')).sum()\n",
    "# correctBusiness = (evaluateData.loc[(evaluateData['Correct'] == True) & (dataFrame['category'] == 'BUSINESS')].all(axis='columns')).sum()\n",
    "# correctSB = (evaluateData.loc[(evaluateData['Correct'] == True) & (dataFrame['category'] == 'STYLE & BEAUTY')].all(axis='columns')).sum()\n",
    "# AllTravelDetected = (evaluateData['Prediction'] == 'TRAVEL').sum()\n",
    "# AllSBDetected = (evaluateData['Prediction'] == 'STYLE & BEAUTY').sum()\n",
    "# AllBusinessDetected = (evaluateData['Prediction'] == 'BUSINESS').sum()\n",
    "# recall1 = (correctTravel) / (AllOfTravel)\n",
    "# recall2 = correctBusiness / AllOfBusiness\n",
    "# recall3 = correctSB / AllOfSB\n",
    "# recall = recall1 + recall2 + recall3\n",
    "# precision1 = (correctTravel) / (AllTravelDetected)\n",
    "# precision2 = correctBusiness / AllBusinessDetected\n",
    "# precision3 = correctSB / AllSBDetected\n",
    "# precision = precision1 + precision2 + precision3\n",
    "# print(accuracy)\n",
    "# print(recall)\n",
    "# print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. On the other hand, Lemmatization reduces the inflected words properly ensuring that the root word belongs to the language. The result of Lemmatization is called lemma which is dictionary form, or citation form of the words. \n",
    "We use Lemmatization in our project because we interested in word frequency and want to treat all forms of a word as one. in stemming some forms of a word may not have the same stem and that can influence the frequency of that word and the accuracy of our model as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf is short for “term frequency-inverse document frequency. which basically reflects how important a word is to a document.\n",
    "tf measures how frequently a term occurs in a document.\n",
    "TF = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "idf measures how important a term is.\n",
    "IDF = $log_e$(Total number of documents / Number of documents with term t in it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('Mehrdad': virtualenv)",
   "language": "python",
   "name": "python37464bitmehrdadvirtualenv5fa8cbb105824cae8f34d6b894d7a675"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
